{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mO5tMMYfI3xn"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = 'sk-proj-D7WRfOUgKX201hJI64VzT3BlbkFJOfSPQCVmhGn6PTS9fXk0'\n",
        "\n",
        "model = \"gpt-3.5-turbo\"\n",
        "\n",
        "prompt = \"Question: John buys a chair. He then buys a table that is 3 times the price of the chair. Then, he buys a couch that is 5 times the price of the table. If John paid $380 for all these items, what is the price of the couch? Answer:\""
      ],
      "metadata": {
        "id": "OsPJcXsmLZof"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_openai(model, prompt, temperature=0.8, top_p=1.0, max_tokens=512, n=3):\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': 'You are an AI assistant'},\n",
        "        {'role': 'user', 'content': prompt}\n",
        "    ]\n",
        "    response = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        max_tokens=max_tokens,\n",
        "        n = n\n",
        "    )\n",
        "    responses = [choice.message.content for choice in response.choices]\n",
        "    return responses"
      ],
      "metadata": {
        "id": "rR9xM1rpI-Wm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responses = chat_with_openai(model, prompt)\n",
        "for i, r in enumerate(responses, 1):\n",
        "    print(f\"response{i}:\\n\\n{r}\")\n",
        "    print(\"\\n\\n\")"
      ],
      "metadata": {
        "id": "n0gVcu-mL6dF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}